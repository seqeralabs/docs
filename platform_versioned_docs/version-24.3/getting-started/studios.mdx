---
title: "Studios for interactive analysis"
description: "An tutorial for creating interactive analysis Studios for Jupyter, RStudio, VSCode, and more"
date: "17 Feb 2025"
tags: [platform, studios, data studios, jupyter, rstudio, xpra, vscode, conda]
toc_max_heading_level: 2
---

Seqera Studios allows users to host a variety of container images in Seqera Platform compute environments for dynamic analysis using popular tools such as Jupyter and RStudio notebooks, Visual Studio Code IDEs, and Xpra remote desktops. Each Studio session provides an individual interactive environment that encapsulates the live environment for real-time data analysis.

In this guide, we'll explore how Seqera Studios seamlessly integrates with your existing workflows, bridging the gap between pipeline execution and interactive analysis. We'll demonstrate how to set up and use different types of Studios, showcasing real-world use cases that highlight the power and flexibility that Studios can bring to your analysis workflows. 

## Overview 

Seqera Studios is a powerful feature of the Seqera Platform that enables seamless integration of interactive analysis environments with your existing bioinformatics workflows. It addresses the common challenge of transitioning between automated pipeline executions and exploratory data analysis, providing a unified solution for the entire data analysis lifecycle.

**Key Features and Benefits**:

- Unified Platform: Host various container images and compute environments in one place.
- Preferred Tools: Support for popular analysis tools like JupyterLab, RStudio, VSCode, and Xpra.
- Seamless Integration: Easily transition from pipeline outputs to interactive analysis.
- Collaboration: Share interactive environments to foster teamwork and knowledge sharing.
- Reproducibility: Version-controlled containers ensure consistent and replicable analyses.
- Cost Efficiency: On-demand, scalable compute environments optimize resource usage.

**Requirements**:

- Valid credentials for your cloud storage account and compute environment
- To create and configure Studios, you need at least the "Maintain" workspace user role
- A workspace compute environment with sufficient resources (recommended minimum: 2 CPUs, 8192 MB memory)
- Data Explorer enabled in your workspace
- Studios currently supports AWS Batch compute environments (without Fargate)


## Jupyter: Python-based visualization of protein structure prediction data 

In this section, we'll demonstrate how to set up a JupyterLab Studio for visualizing results from the [nf-core/proteinfold](https://nf-co.re/proteinfold/1.1.1) pipeline.

### Create a Jupyter notebook studio

From the **Data Studios** tab, select **Add a data studio** and complete the following:
- In the **Compute & Data** tab:
    - Select an AWS Batch compute environment. 
        :::info
        The same compute environment can be used for pipeline execution and running your Studios notebook environment, but Data Studios does not support AWS Fargate. To use one compute environment for both nf-core/proteinfold pipeline execution and your studio, leave **Enable Fargate for head job** disabled. Alternatively, create a second basic AWS Batch compute environment with at least 2 CPUs and 8192 MB of RAM for your studio.
        :::
    - Optional: Enter CPU and memory allocations. The default values are 2 CPUs and 8192 MB memory (RAM).
        :::note
        Studios compete for computing resources when sharing compute environments. Ensure your compute environment has sufficient resources to run both your pipelines and data studio sessions. 
        :::
    - Mount data using Data Explorer: Mount the S3 bucket or directory path that contains the pipeline work directory of your Proteinfold run. 
- In the **General config** tab:
    - Select the latest **Jupyter** container image template from the list.
    - Optional: Enter a unique name and description for the data studio. 
    - Check **Install Conda packages** and paste the following Conda environment YAML snippet:

    ```yaml 
    channels:
      - bioconda
      - conda-forge
    dependencies:
      - python=3.10
      - conda-forge::biopython=1.84
      - conda-forge::nglview=3.1.2
      - conda-forge::ipywidgets=8.1.5
    ```

- Confirm the data studio details in the **Summary** tab
- Select **Add** or choose to **Add and start** the studio immediately.
- If you chose to **Add** the studio in the preceding step, select **Connect** in the options menu to open the studio in a new browser tab. 

![Add data studio](./_images/add-ds-pf.gif)

### Visualize protein structures 

The Jupyter environment can be configured with the packages and scripts you need for interactive analysis. For the purposes of this guide, run the following scripts in individual code cells to install the necessary packages and perform visualization:

1. Import libraries and check versions:

    ```python 
    TODO
    ```

1. Define visualization functions:

    ```python 
    TODO
    ```

1. Set up file paths and create file dictionary:

    ```python 
    TODO
    ```    

1. Display file information:

    ```python
    TODO
    ```

1. Visualize structures:

    ```python
    TODO
    ```

1. Add interactive elements:

    ```python
    TODO
    ```

1. Display usage instructions:

    ```python
    TODO
    ```

![Protein structure visualization](./_images/protein-structure-visualization.gif)

## RStudio: Analyze RNASeq data and differential expression statistics 

In this section, we have run the **nf-core/rnaseq** pipeline to quantify gene expression in RNA sequencing data, followed by **nf-core/differentialabundance** to derive differential expression statistics. This section demonstrates how to create a studio to perform further analysis with these results from cloud storage. One of these outputs is an RShiny application that can be deployed for interactive analysis.

### Create an RStudio notebook studio 

From the **Data Studios** tab, select **Add a data studio** and complete the following:
- Select the latest **RStudio** container image template from the list.
- Select your AWS Batch compute environment. 
:::note
Data studios compete for computing resources when sharing compute environments. Ensure your compute environment has sufficient resources to run both your pipelines and data studio sessions. The default CPU and memory allocation for a data studio is 2 CPUs and 8192 MB RAM. 
:::
- Mount data using Data Explorer: Mount the S3 bucket or directory path that contains the results of your nf-core/differentialabundance pipeline run. 
- Optional: Enter CPU and memory allocations. The default values are 2 CPUs and 8192 MB memory (RAM).
- Select **Add** or choose to **Add and start** the studio immediately.
- If you chose to **Add** the studio in the preceding step, select **Start** in the options menu, then **Connect** to open the studio in a new browser tab when it is running. 

![Add data studio](./_images/create-ds.gif)

### Perform the analysis and explore results

1. Configure the RStudio environment with installed packages, including ShinyNGS:

    ```r 
    if (!require("BiocManager", quietly = TRUE))
      install.packages("BiocManager")

    BiocManager::install(version = "3.11", ask = FALSE)
    BiocManager::install(c("SummarizedExperiment", "GSEABase", "limma"))

    install.packages(c("devtools", "matrixStats", "rmarkdown", "markdown"))
    install.packages("shiny", repos = "https://cran.rstudio.com/")

    devtools::install_version("cpp11", version = "0.2.1", repos = "http://cran.us.r-project.org")
    devtools::install_github('pinin4fjords/shinyngs', upgrade_dependencies = FALSE)
    ```

1. Download the RDS file from your nf-core/differentialabundance results (see [Shiny app](https://nf-co.re/differentialabundance/1.5.0/docs/output/#shiny-app) from the nf-core documentation for file details): 

    ```r 
    download.file("https://your-bucket.your-s3-region.amazonaws.com/differentialabundance/your-results/shinyngs_app/you-study-name/data.rds", 'data.rds')
    ```

1. Import libraries, read your RDS data, and launch the RShiny app:

    ```r 
    library(shinyngs)
    library(markdown)
    esel <- readRDS("data.rds")
    app <- prepareApp("rnaseq", esel)
    shiny::shinyApp(app$ui, app$server)
    ```

![Explore the RShiny app](./quickstart-demo/assets/rnaseq-diffab-rshiny-app-explore.gif)

## Xpra: Interactive digital pathology analysis of cancer imaging data

In this section, we'll explore how Studios and Xpra remote desktop technology enables interactive digital pathology analysis using QuPath, a powerful open-source software for bioimage analysis. We'll demonstrate how to set up an Xpra environment, install QuPath, and analyze cancer imaging data from the Imaging Data Commons (IDC). See [Using QuPath for visualization](https://learn.canceridc.dev/tutorials/slide-microscopy/qpath-for-sm-visualization) for the full IDC tutorial. 

### Add public cloud data using Data Explorer

For the purposes of following the [IDC visualization tutorial](https://learn.canceridc.dev/tutorials/slide-microscopy/qpath-for-sm-visualization), you must add the public IDC cancer data S3 bucket to your workspace using Data Explorer:

1. From the **Data Explorer** tab, select **Add cloud bucket**. 
1. Specify the bucket details:
    - **Provider**: AWS
    - **Bucket path**: `s3://idc-open-data/`
    - A unique **Name** for the bucket, such as `idc-open-data`.
    - **Credentials**: Select **Public** from the dropdown menu.
    - An optional bucket **Description**.
1. Select **Add**.

### Create an Xpra studio 

From the **Data Studios** tab, select **Add a data studio** and complete the following:
- Select the latest **Xpra** container image template from the list.
- Select your AWS Batch compute environment. 
:::note
Studios compete for computing resources when sharing compute environments. Ensure your compute environment has sufficient resources to run both your pipelines and data studio sessions. The default CPU and memory allocation for a studio is 2 CPUs and 8192 MB RAM. 
:::
- Mount data using Data Explorer: For the purposes of this guide, mount the IDC open data S3 bucket you added previously. 
- Optional: Enter CPU and memory allocations.
- Select **Add** or choose to **Add and start** the studio immediately.
- If you chose to **Add** the studio in the preceding step, select **Connect** in the options menu to open the studio in a new browser tab. 

### Perform the analysis and explore results 

1. Configure the Xpra environment by installing QuPath:

    ```shell
    sudo apt install xz-utils
    wget https://github.com/qupath/qupath/releases/download/v0.5.1/QuPath-v0.5.1-Linux.tar.xz
    tar -xf QuPath-v0.5.1-Linux.tar.xz
    chmod u+x ./QuPath/bin/QuPath
    ```

1. TODO

## VS Code: Create a Python Conda environment with nf-core tools to develop Nextflow pipelines 

### Create a VS Code studio 

### Customize your development environment