---
title: Azure Batch
description: "Use Fusion with Azure Batch and Azure Blob storage"
date: "23 Aug 2024"
tags: [fusion, storage, compute, azure batch, blob storage]
---

Fusion simplifies and improves the efficiency of Nextflow pipelines in [Azure Batch](https://azure.microsoft.com/en-us/products/batch) in several ways:

- No need to use the Azure CLI tool for copying data to and from Azure Blob Storage.
- No need to create custom containers to include the Azure CLI tool.
- Fusion uses an efficient data transfer and caching algorithm that provides much faster throughput compared to Azure CLI and does not require a local copy of data files.
- Replacing the Azure CLI with a native API client, the transfer is much more robust at scale.

### Platform Azure Batch compute environments 

Seqera Platform supports Fusion in Batch Forge and manual Azure Batch compute environments. 

See [Azure Batch](https://docs.seqera.io/platform/latest/compute-envs/azure-batch) for compute and storage recommendations and instructions to enable Fusion.

### Nextflow CLI

:::tip
We recommend selecting machine types with a local temp storage disk of at least 200 GB and a random read speed of 1000 MBps or more for large and long-lived production pipelines. The suffix `d` after the core number (e.g., `Standard_E16*d*_v5`) denotes a VM with a local temp disk. Select instances with Standard SSDs â€” Fusion does not support Azure network-attached storage (Premium SSDv2, Ultra Disk, etc.). Larger local storage increases Fusion's throughput and reduces the chance of overloading the machine. See [Sizes for virtual machines in Azure](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/overview) for more information.
:::

1. Add the following to your `nextflow.conf` file:

    ```groovy
    fusion.enabled = true
    wave.enabled = true
    process.executor = 'azure-batch'
    ```

1. Run the pipeline with the usual run command:

    ```
    nextflow run <YOUR PIPELINE SCRIPT> -w az://<YOUR CONTAINER>/scratch
    ```

    Replace `<YOUR PIPELINE SCRIPT>` with your pipeline Git repository URI and `<YOUR CONTAINER>` with your Blob Storage container.